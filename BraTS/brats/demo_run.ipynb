{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you've never installed these stuffs...\n",
    "!sudo apt-get install ants\n",
    "!pip install nipype\n",
    "\n",
    "!sudo apt-get install libhdf5-serial-dev\n",
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n4itk bias correction\n",
    "from preprocess import convert_brats_data\n",
    "# training dataset\n",
    "convert_brats_data('../data/original/','../data/preprocessed/')\n",
    "# validation dataset\n",
    "convert_brats_data('../data/val_data/','../data/preprocessed_val_data/')\n",
    "\n",
    "# # if you wanna get rid of bias correction, just do this:\n",
    "# convert_brats_data('../data/original/','../data/preprocessed/',bias_correct=False)\n",
    "# convert_brats_data('../data/val_data/','../data/preprocessed_val_data/',bias_correct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import train_model\n",
    "train_model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was used for training process before the launch of validation dataset\n",
    "import predict_model\n",
    "predict_model.main()\n",
    "import evaluate\n",
    "evaluate.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is used to generate the final prediction results for uploading\n",
    "import run_validation\n",
    "# for val/test dataset:\n",
    "run_validation.main_run()\n",
    "# for training dataset:\n",
    "run_validation.predict_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to draw the figures of evaluation results\n",
    "\n",
    "from draw_evaluation import draw_evaluate, four_in_all\n",
    "# # for training dataset\n",
    "# source_fold = './results/val/Stats_Training_final.csv'\n",
    "# dest_fold = './saves/training_figs'\n",
    "# draw_evaluate(source_fold,dest_fold,val=False)\n",
    "# four_in_all(dest_fold)\n",
    "# for val/test dataset\n",
    "source_fold = './results/val/Stats_Validation_final.csv'\n",
    "dest_fold = './saves/val_figs'\n",
    "draw_evaluate(source_fold,dest_fold)\n",
    "four_in_all(dest_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (option) for cross validation\n",
    "from cross_val import generate_cross_val_fold\n",
    "generate_cross_val_fold()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
